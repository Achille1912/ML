--------------------------------------------------------------------------------
2025-06-18 16:04:44,543 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-06-18 16:04:44,550 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-06-18 16:05:29,907 - INFO - 
--- Evaluation: XGBoost ---
Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.58      0.66       268
           1       0.87      0.90      0.89       268
           2       0.78      0.86      0.82       268
           3       0.90      0.96      0.93       268
           4       0.93      0.96      0.95       268
           5       0.96      0.98      0.97       268

    accuracy                           0.87      1608
   macro avg       0.87      0.87      0.87      1608
weighted avg       0.87      0.87      0.87      1608

Confusion Matrix:
[[155  25  49  20  11   8]
 [ 11 242   8   1   4   2]
 [ 25   6 230   4   2   1]
 [  5   3   3 257   0   0]
 [  4   2   1   2 258   1]
 [  1   0   2   1   1 263]]
Balanced Accuracy: 0.8737562189054726
F1 Macro: 0.8690149158135193
--------------------------------------------------------------------------------
2025-06-18 16:05:43,115 - INFO - 
--- Evaluation: Random Forest ---
Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.62      0.69       268
           1       0.86      0.90      0.88       268
           2       0.83      0.87      0.85       268
           3       0.90      0.97      0.93       268
           4       0.94      0.94      0.94       268
           5       0.95      0.99      0.97       268

    accuracy                           0.88      1608
   macro avg       0.88      0.88      0.88      1608
weighted avg       0.88      0.88      0.88      1608

Confusion Matrix:
[[165  26  37  21  10   9]
 [ 15 240   6   1   2   4]
 [ 23   7 232   4   2   0]
 [  3   2   1 261   1   0]
 [  4   4   3   4 252   1]
 [  1   0   0   0   1 266]]
Balanced Accuracy: 0.8805970149253731
F1 Macro: 0.8766040083239668
--------------------------------------------------------------------------------
2025-06-18 16:05:48,780 - INFO - 
--- Evaluation: SVM ---
Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.42      0.54       268
           1       0.82      0.95      0.88       268
           2       0.79      0.82      0.80       268
           3       0.89      0.97      0.93       268
           4       0.90      0.97      0.93       268
           5       0.91      0.97      0.94       268

    accuracy                           0.85      1608
   macro avg       0.84      0.85      0.84      1608
weighted avg       0.84      0.85      0.84      1608

Confusion Matrix:
[[113  47  43  23  22  20]
 [  4 255   6   0   1   2]
 [ 26   8 219   7   5   3]
 [  3   1   2 261   1   0]
 [  0   1   3   3 260   1]
 [  3   0   5   0   0 260]]
Balanced Accuracy: 0.8507462686567164
F1 Macro: 0.8374168444093323
--------------------------------------------------------------------------------
2025-06-18 16:05:49,342 - INFO - 
--- Evaluation: Logistic Regression ---
Classification Report:
              precision    recall  f1-score   support

           0       0.33      0.28      0.30       268
           1       0.49      0.58      0.53       268
           2       0.26      0.15      0.19       268
           3       0.41      0.49      0.45       268
           4       0.45      0.46      0.46       268
           5       0.56      0.68      0.62       268

    accuracy                           0.44      1608
   macro avg       0.42      0.44      0.42      1608
weighted avg       0.42      0.44      0.42      1608

Confusion Matrix:
[[ 74  39  33  50  28  44]
 [ 27 156  16  17  26  26]
 [ 45  52  39  66  47  19]
 [ 19  16  36 130  35  32]
 [ 18  37  23  45 124  21]
 [ 42  16   2   8  17 183]]
Balanced Accuracy: 0.43905472636815923
F1 Macro: 0.42315863339320536
--------------------------------------------------------------------------------
2025-06-18 16:05:49,857 - INFO - 
--- Evaluation: KNN ---
Classification Report:
              precision    recall  f1-score   support

           0       0.88      0.28      0.42       268
           1       0.81      0.96      0.88       268
           2       0.84      0.94      0.88       268
           3       0.87      0.99      0.93       268
           4       0.89      1.00      0.94       268
           5       0.89      0.99      0.94       268

    accuracy                           0.86      1608
   macro avg       0.86      0.86      0.83      1608
weighted avg       0.86      0.86      0.83      1608

Confusion Matrix:
[[ 74  57  45  32  29  31]
 [  2 258   4   0   2   2]
 [  7   2 251   6   1   1]
 [  1   1   0 266   0   0]
 [  0   0   0   1 267   0]
 [  0   1   0   1   0 266]]
Balanced Accuracy: 0.859452736318408
F1 Macro: 0.8314252145583804
--------------------------------------------------------------------------------
2025-06-18 16:05:49,860 - INFO - 
Confronto Finale:
                 Model                                        Best Params  \
1        Random Forest  {'selector__k': 'all', 'classifier__n_estimato...   
0              XGBoost  {'classifier__n_estimators': 300, 'classifier_...   
2                  SVM  {'pca__n_components': None, 'classifier__kerne...   
4                  KNN  {'classifier__weights': 'distance', 'classifie...   
3  Logistic Regression  {'selector__k': 'all', 'classifier__solver': '...   

   Balanced Accuracy  F1 Macro  
1           0.880597  0.876604  
0           0.873756  0.869015  
2           0.850746  0.837417  
4           0.859453  0.831425  
3           0.439055  0.423159  
