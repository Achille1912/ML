{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749596d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file salvato in: logs/20250701_214005/model_evaluation.log\n",
      "\n",
      "========================================\n",
      "Training Stage 1: Healthy vs Infected\n",
      "========================================\n",
      "\n",
      "--- Evaluation: Stage 1 - Healthy vs Infected ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.77      0.43       488\n",
      "           1       0.99      0.94      0.96     14214\n",
      "\n",
      "    accuracy                           0.93     14702\n",
      "   macro avg       0.65      0.86      0.70     14702\n",
      "weighted avg       0.97      0.93      0.95     14702\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  378   110]\n",
      " [  874 13340]]\n",
      "Balanced Accuracy: 0.8565507453976338\n",
      "F1 Macro: 0.6994565325781297\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "========================================\n",
      "Training Stage 2: Infected Subtype Classification\n",
      "========================================\n",
      "\n",
      "--- Evaluation: Stage 2 - Infected Subtypes ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13333\n",
      "           1       0.07      0.57      0.12         7\n",
      "\n",
      "    accuracy                           1.00     13340\n",
      "   macro avg       0.53      0.78      0.56     13340\n",
      "weighted avg       1.00      1.00      1.00     13340\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13276    57]\n",
      " [    3     4]]\n",
      "Balanced Accuracy: 0.7835767322754497\n",
      "F1 Macro: 0.5576962184242402\n",
      "--------------------------------------------------------------------------------\n",
      "âœ… Pipeline completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "# === Create timestamped logging folder ===\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_dir = f\"logs/{timestamp}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# === Logging setup (robusto) ===\n",
    "log_file = os.path.join(log_dir, \"model_evaluation.log\")\n",
    "\n",
    "# Rimuove handler pre-esistenti (es. da Jupyter o da un run precedente)\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Configura logging verso file\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Test immediato per confermare che il file venga scritto\n",
    "logging.info(\"Logger inizializzato con successo.\")\n",
    "\n",
    "\n",
    "print(f\"Log file salvato in: {log_file}\")\n",
    "\n",
    "def save_plot(fig, name):\n",
    "    fig_path = os.path.join(log_dir, name)\n",
    "    fig.savefig(fig_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "def recode_labels_for_first_classifier(y):\n",
    "    return np.where((y == 1) | (y == 7), 1, 0)\n",
    "\n",
    "def filter_data_for_second_classifier(X, y):\n",
    "    mask = (y == 1) | (y == 7)\n",
    "    return X[mask], y[mask]\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    log_msg = (\n",
    "        f\"\\n--- Evaluation: {model_name} ---\\n\"\n",
    "        f\"Classification Report:\\n{report}\\n\"\n",
    "        f\"Confusion Matrix:\\n{matrix}\\n\"\n",
    "        f\"Balanced Accuracy: {bal_acc}\\n\"\n",
    "        f\"F1 Macro: {f1}\\n\"\n",
    "        + \"-\"*80\n",
    "    )\n",
    "    logging.info(log_msg)\n",
    "    print(log_msg)\n",
    "\n",
    "# Pipeline 1: XGBoost \n",
    "def create_xgb_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', BorderlineSMOTE(random_state=42)),\n",
    "        ('varthresh', VarianceThreshold(threshold=1e-5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(score_func=f_classif, k=100)),\n",
    "        ('lda', LinearDiscriminantAnalysis(solver='svd', n_components=num_class-1)),\n",
    "        ('classifier', XGBClassifier(eval_metric='mlogloss', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    param_dist = {\n",
    "        'selector__k': [700],\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [3, 6, 10],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "    \n",
    "    return pipeline, param_dist\n",
    "\n",
    "# Pipeline 2: Random Forest\n",
    "def create_rf_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', BorderlineSMOTE(random_state=42)),\n",
    "        ('varthresh', VarianceThreshold(threshold=1e-5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(score_func=f_classif)),\n",
    "        ('lda', LinearDiscriminantAnalysis(solver='svd', n_components=num_class-1)),\n",
    "        ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    param_dist = {\n",
    "        'selector__k': [700],\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [None, 5, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    return pipeline, param_dist\n",
    "\n",
    "# Pipeline 3: SVM \n",
    "def create_svm_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', BorderlineSMOTE(random_state=42)),\n",
    "        ('varthresh', VarianceThreshold(threshold=1e-5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(score_func=f_classif, k=100)),\n",
    "        ('lda', LinearDiscriminantAnalysis(solver='svd', n_components=num_class-1)),\n",
    "        ('classifier', SVC(random_state=42, class_weight='balanced', kernel='linear'))\n",
    "    ])\n",
    "\n",
    "    param_dist = {\n",
    "        'selector__k': [700],\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'classifier__gamma': ['scale', 'auto']  # Only relevant for rbf and poly kernels\n",
    "    }\n",
    "    return pipeline, param_dist\n",
    "\n",
    "# Pipeline 4: Logistic Regression \n",
    "def create_lr_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', BorderlineSMOTE(random_state=42)),\n",
    "        ('varthresh', VarianceThreshold(threshold=1e-5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(score_func=f_classif, k=100)),\n",
    "        ('lda', LinearDiscriminantAnalysis(solver='svd', n_components=num_class-1)),\n",
    "        ('classifier', LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    param_dist = {\n",
    "        'selector__k': [700],\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    \n",
    "    return pipeline, param_dist\n",
    "\n",
    "# Pipeline 5: KNN\n",
    "def create_knn_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', BorderlineSMOTE(random_state=42)),\n",
    "        ('varthresh', VarianceThreshold(threshold=1e-5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(score_func=f_classif, k=100)),\n",
    "        ('lda', LinearDiscriminantAnalysis(solver='svd', n_components=num_class-1)),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    param_dist = {\n",
    "        'selector__k': [700],\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'classifier__p': [1, 2]  # 1: manhattan, 2: euclidean\n",
    "    }\n",
    "    \n",
    "    return pipeline, param_dist\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(\"../roi_features_train.csv\")\n",
    "    X = df.drop(columns=[\"image_id\", \"score\", \"x1\", \"y1\", \"x2\", \"y2\", \"label\"])\n",
    "    y_original = df[\"label\"]\n",
    "\n",
    "    # ========== Stage 1: Healthy (RBC+WBC) vs Infected ==========\n",
    "    y_stage1 = recode_labels_for_first_classifier(y_original)\n",
    "\n",
    "    # Encode y_stage1 to 0/1\n",
    "    le_stage1 = LabelEncoder()\n",
    "    y_stage1 = le_stage1.fit_transform(y_stage1)\n",
    "\n",
    "    # Train-test split for Stage 1\n",
    "    X_train_stage1, X_test_stage1, y_train_stage1, y_test_stage1 = train_test_split(\n",
    "        X, y_stage1, test_size=0.2, stratify=y_stage1, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'='*40}\\nTraining Stage 1: Healthy vs Infected\\n{'='*40}\")\n",
    "    pipeline_stage1, param_dist_stage1 = create_rf_pipeline()\n",
    "\n",
    "    search_stage1 = RandomizedSearchCV(\n",
    "        pipeline_stage1,\n",
    "        param_distributions=param_dist_stage1,\n",
    "        cv=3,\n",
    "        n_iter=3,\n",
    "        scoring='f1_macro',\n",
    "        random_state=42\n",
    "    )\n",
    "    search_stage1.fit(X_train_stage1, y_train_stage1)\n",
    "    best_model_stage1 = search_stage1.best_estimator_\n",
    "\n",
    "    logging.info(f\"[Stage 1] Best Parameters: {search_stage1.best_params_}\")\n",
    "    evaluate_model(best_model_stage1, X_test_stage1, y_test_stage1, model_name=\"Stage 1 - Healthy vs Infected\")\n",
    "\n",
    "    # ========== Stage 2: Infected Subtypes Only ==========\n",
    "    # Predict on X_test_stage1 to find infected samples\n",
    "    y_pred_stage1 = best_model_stage1.predict(X_test_stage1)\n",
    "    infected_indices = np.where(y_pred_stage1 == 1)[0]\n",
    "\n",
    "    if len(infected_indices) == 0:\n",
    "        print(\"No infected cells predicted by Stage 1 on the test set.\")\n",
    "        return\n",
    "\n",
    "    # Step 1: Filter training infected samples\n",
    "    X_train_stage2, y_train_stage2_raw = filter_data_for_second_classifier(\n",
    "        X_train_stage1, y_original.iloc[X_train_stage1.index]\n",
    "    )\n",
    "\n",
    "    # Step 2: Fit LabelEncoder on training infected labels\n",
    "    le_stage2 = LabelEncoder()\n",
    "    y_train_stage2 = le_stage2.fit_transform(y_train_stage2_raw)\n",
    "\n",
    "    # Step 3: Filter test infected predictions\n",
    "    X_test_stage2_all = X_test_stage1.iloc[infected_indices]\n",
    "    y_test_stage2_raw_all = y_original.iloc[X_test_stage2_all.index]\n",
    "\n",
    "    # Step 4: Keep only labels seen during training\n",
    "    valid_mask = y_test_stage2_raw_all.isin(le_stage2.classes_)\n",
    "    X_test_stage2 = X_test_stage2_all[valid_mask]\n",
    "    y_test_stage2_raw = y_test_stage2_raw_all[valid_mask]\n",
    "    y_test_stage2 = le_stage2.transform(y_test_stage2_raw)\n",
    "\n",
    "    if len(X_test_stage2) == 0:\n",
    "        print(\"No valid infected subtype labels in test set after filtering.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*40}\\nTraining Stage 2: Infected Subtype Classification\\n{'='*40}\")\n",
    "    pipeline_stage2, param_dist_stage2 = create_svm_pipeline()\n",
    "\n",
    "    search_stage2 = RandomizedSearchCV(\n",
    "        pipeline_stage2,\n",
    "        param_distributions=param_dist_stage2,\n",
    "        cv=3,\n",
    "        n_iter=3,\n",
    "        scoring='f1_macro',\n",
    "        random_state=42\n",
    "    )\n",
    "    search_stage2.fit(X_train_stage2, y_train_stage2)\n",
    "    best_model_stage2 = search_stage2.best_estimator_\n",
    "\n",
    "    logging.info(f\"[Stage 2] Best Parameters: {search_stage2.best_params_}\")\n",
    "    evaluate_model(best_model_stage2, X_test_stage2, y_test_stage2, model_name=\"Stage 2 - Infected Subtypes\")\n",
    "\n",
    "    # Final Log Summary\n",
    "    logging.info(\"\\nPipeline Completed Successfully.\")\n",
    "    print(\"âœ… Pipeline completed successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
